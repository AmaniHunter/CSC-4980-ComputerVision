{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "\n",
    "# Start defining a pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "#Define a source - color camera\n",
    "cam_rgb = pipeline.createColorCamera()\n",
    "cam_rgb.setPreviewSize(600, 600)\n",
    "cam_rgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "cam_rgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "cam_rgb.setInterleaved(False)\n",
    "cam_rgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.RGB)\n",
    "\n",
    "# Create output\n",
    "xout_rgb = pipeline.createXLinkOut()\n",
    "xout_rgb.setStreamName(\"rgb\")\n",
    "cam_rgb.preview.link(xout_rgb.input)\n",
    "\n",
    "# Define a source - two mono (grayscale) cameras\n",
    "left = pipeline.createMonoCamera()\n",
    "left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_720_P)\n",
    "left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "\n",
    "right = pipeline.createMonoCamera()\n",
    "right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_720_P)\n",
    "right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "\n",
    "# Create a node that will produce the depth map (using disparity output as it's easier to visualize depth this way)\n",
    "depth = pipeline.createStereoDepth()\n",
    "depth.setConfidenceThreshold(200)\n",
    "left.out.link(depth.left)\n",
    "right.out.link(depth.right)\n",
    "\n",
    "\n",
    "# Create output\n",
    "xout = pipeline.createXLinkOut()\n",
    "xout.setStreamName(\"disparity\")\n",
    "depth.disparity.link(xout.input)\n",
    "\n",
    "# Pipeline defined, now the device is connected to\n",
    "with dai.Device(pipeline) as device:\n",
    "    # Start pipeline\n",
    "    device.startPipeline()\n",
    "\n",
    "    # Output queue will be used to get the rgb frames from the output defined above\n",
    "    q_rgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "\n",
    "    # Output queue will be used to get the disparity frames from the outputs defined above\n",
    "    q = device.getOutputQueue(name=\"disparity\", maxSize=4, blocking=False)\n",
    "\n",
    "    while True:\n",
    "        in_rgb = q_rgb.get()  # blocking call, will wait until a new data has arrived\n",
    "        #print(in_rgb.getFps())\n",
    "        # Retrieve 'bgr' (opencv format) frame\n",
    "        cv2.imshow(\"bgr\", in_rgb.getCvFrame())\n",
    "\n",
    "        in_depth = q.get()  # blocking call, will wait until a new data has arrived\n",
    "        # data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "        frame = in_depth.getData().reshape((in_depth.getHeight(), in_depth.getWidth())).astype(np.uint8)\n",
    "        frame = np.ascontiguousarray(frame)\n",
    "        # frame is transformed, the color map will be applied to highlight the depth info\n",
    "        frame = cv2.applyColorMap(frame, cv2.COLORMAP_JET)\n",
    "        # frame is ready to be shown\n",
    "        cv2.imshow(\"disparity\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}