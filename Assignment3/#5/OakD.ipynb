{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "camRgb = pipeline.create(dai.node.ColorCamera)\n",
    "xoutVideo = pipeline.create(dai.node.XLinkOut)\n",
    "\n",
    "xoutVideo.setStreamName(\"face detector\")\n",
    "\n",
    "camRgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "camRgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "camRgb.setVideoSize(860, 720)\n",
    "\n",
    "xoutVideo.input.setBlocking(False)\n",
    "xoutVideo.input.setQueueSize(1)\n",
    "\n",
    "camRgb.video.link(xoutVideo.input)\n",
    "\n",
    "amani_image = face_recognition.load_image_file(\"Amani_pic.jpeg\")\n",
    "amani_face_encoding = face_recognition.face_encodings(amani_image)[0]\n",
    "\n",
    "known_face_encodings = [\n",
    "    amani_face_encoding,\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Amani Hunter\"\n",
    "]\n",
    "val = input(\"Enter name of person to detect: \")\n",
    "print(val)\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "top_lip = []\n",
    "bottom_lip = []\n",
    "center_points = []\n",
    "process_this_frame = True\n",
    "\n",
    "with dai.Device(pipeline) as device:\n",
    "    video = device.getOutputQueue(name=\"face detector\", maxSize=1, blocking=False)\n",
    "\n",
    "    while True:\n",
    "        videoIn = video.get()\n",
    "        frame = videoIn.getCvFrame()\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        if process_this_frame:\n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "            face_landmarks_list = face_recognition.face_landmarks(rgb_small_frame)\n",
    "            face_names = []\n",
    "            for index, face_encoding in enumerate(face_encodings):\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                name = \"Unknown Individual\"\n",
    "\n",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                if name == 'Amani Hunter' and val == name:\n",
    "                    keys = list(face_landmarks_list[index].keys())\n",
    "                    top_lip = face_landmarks_list[index][keys[-2]]\n",
    "                    bottom_lip = face_landmarks_list[index][keys[-1]]\n",
    "                    top_lip = np.array(top_lip, dtype=np.int32)\n",
    "                    bottom_lip = np.array(bottom_lip, dtype=np.int32)\n",
    "                    top_lip = top_lip * 4\n",
    "                    bottom_lip = bottom_lip * 4\n",
    "                    center_top_lip = np.mean(top_lip, axis=0)\n",
    "                    center_top_lip = center_top_lip.astype('int')\n",
    "                    center_points.append(center_top_lip)\n",
    "                face_names.append(name)\n",
    "        process_this_frame = not process_this_frame\n",
    "\n",
    "       # cv2.polylines(frame, np.array([top_lip]), 1, (255, 255, 255))\n",
    "        #cv2.polylines(frame, np.array([bottom_lip]), 1, (255, 255, 255))\n",
    "        for i in range(1, len(center_points)):\n",
    "            if center_points[i - 1] is None or center_points[i] is None:\n",
    "                continue\n",
    "           # cv2.line(frame, tuple(center_points[i - 1]), tuple(center_points[i]), (0, 0, 255), 2)\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('Face Detector', frame)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}